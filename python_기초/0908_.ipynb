{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab274b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbcf0f5",
   "metadata": {},
   "source": [
    "```\n",
    "AI : 인간의 의도에 따라 답을 구하는 알고리즘들\n",
    "ML : 단순하게 그래프를 구현하고 답을 구하는 데 최적화\n",
    "DL : Dense를 쌓아서 기존 단순한 그래프를 여러 차원에 올려서 답을 구하는 형태\n",
    "\n",
    "선생님 답변\n",
    "AI : 인간을 모사하는 지능, 인간을 따라하는,\n",
    "ML : TP Task Performance Experience 데이터를 통해 성능을 높이는 행위\n",
    "DL : 신경망, Dense 은닉층을 쌓아서(4계층) MLP 퍼셉트론 주로 비정형데이터\n",
    "\n",
    "데이터셋 구축이 필요하다\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c30619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed7a63e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m cpu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      4\u001b[0m gpu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(cpu)\n",
      "\u001b[1;31mAcceleratorError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cpu = torch.FloatTensor([1, 2, 3])\n",
    "gpu = torch.cuda.FloatTensor([1, 2, 3])\n",
    "tensor = torch.rand((1, 1), device=device)\n",
    "print(device)\n",
    "print(cpu)\n",
    "print(gpu)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3906abd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
